{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8cFJc0qToTdi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split,cross_val_score\n",
        "from sklearn import datasets\n",
        "from sklearn.metrics import accuracy_score\n",
        "from random import choices , randint, randrange , random,uniform\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier,plot_tree\n",
        "from operator import itemgetter\n",
        "\n",
        "\n",
        "# Define the genetic algorithm parameters\n",
        "population_size = [5,7]\n",
        "generation_size = [10,20]\n",
        "mutation_rate = 0.02\n",
        "# best_feature_score_list=[]\n",
        "\n",
        "#this function will generate a list of 0 and 1,of lenght equal to the total number of chromosomes in dataset\n",
        "#basically it will create our chromosome..\n",
        "def generate_chromosome(x_df):\n",
        "    return [randint(0, 1) for _ in range(x_df.shape[1])]\n",
        "\n",
        "\n",
        "#this population will create our population\n",
        "#it will call generate_chromosome() function number of times = population_size and and append all chromosome into list return a population\n",
        "\n",
        "def init_population(population_size,x_df):\n",
        "  population = []\n",
        "  for i in range(population_size):\n",
        "    chromosome=generate_chromosome(x_df)\n",
        "    population.append(chromosome)\n",
        "  return population\n",
        "\n",
        "\n",
        "\n",
        "#convert actual chromosome into seleccted features dataframe\n",
        "#this function will iterate over our chromosome and the indices it will find 1, it will add the feature of that indices to our\n",
        "#new DataFrame\n",
        "\n",
        "def select_feature(chromosome,x_df):\n",
        "  new_df=pd.DataFrame()\n",
        "  for i in range(len(chromosome)):\n",
        "    if(chromosome[i]==1):\n",
        "      column_name=x_df.columns[i]       # ith column name extract from the dataframe x_df\n",
        "      data=x_df[column_name]            #with the help of column_name extact column data\n",
        "      new_df[column_name]=data          #data will insert into new dataframe\n",
        "  # print(new_df.shape)\n",
        "  return new_df\n",
        "\n",
        "\n",
        "def fitness_function(chromosome,x_df,y_df):\n",
        "  ct=0\n",
        "  for i in chromosome:        #if chromosome generate[0,0,0,0,......] No feature selected thorw error\n",
        "    if i==0:\n",
        "      ct+=1\n",
        "\n",
        "  if ct== len(chromosome):          #if count is equal to length of chromosome flip 0th bit\n",
        "    chromosome[0]=1\n",
        "\n",
        "  select_feature_df=pd.DataFrame()\n",
        "  select_feature_df=select_feature(chromosome,x_df)      #returns selected features DataFrame\n",
        "\n",
        "  xtrain , xtest, ytrain, ytest = train_test_split(select_feature_df, y_df)            #split selected feature dataframe traing and testing\n",
        "\n",
        "  clf=DecisionTreeClassifier()        #create DecisionTreeClassifier\n",
        "\n",
        "  clf.fit(xtrain,ytrain)      #train classifier\n",
        "  y_predict=clf.predict(xtest)\n",
        "  score=accuracy_score(ytest,y_predict)    #calculate accuracy score between test target and predicted target\n",
        "  return score\n",
        "\n",
        "\n",
        "\n",
        "#this function will divide our population into two parts fit and unfit, it will send the fit ones to the production\n",
        "# and it wil discrad the unfit one---- survival of the fittest\n",
        "\n",
        "def selection(population,x_df,y_df):        #initial population selection\n",
        "  fitness_score=[]\n",
        "  for chromosome in population:       #for each chromosome in the populaton we will calculate it's fitness score\n",
        "    score=fitness_function(chromosome,x_df,y_df)        #fitness function calculate chromosome(list) fitness score\n",
        "    fitness_score.append(score)         #and we will append it to the list..\n",
        "  indx=np.argsort(fitness_score)[::-1]  #sort fitness score in desending order and the get he indexes of them ..\n",
        "                                        #through these index we select those population which is more fit\n",
        "\n",
        "  selected_population=[]\n",
        "  for i in indx[:int(len(population)/2)]:      # Itreate loop to half of the population and discard those population who is less fit\n",
        "    selected_population.append(population[i])   #now based on the above sorted indexes of fitness_score, select popolation which generate heigher fitness score\n",
        "\n",
        "  # best_feature_score_list.append([k,selected_population[0],fitness_function(selected_population[0],x_df,y_df)]) #here we are addign best of each generation into our list for further knowledge\n",
        "  return selected_population\n",
        "\n",
        "\n",
        "#this function will use the roullete wheel method to pick the parents further for the crossover..\n",
        "\n",
        "def select_parent(population,x_df,y_df):\n",
        "  fit_score=[]\n",
        "  for chromosome in population:\n",
        "    score=fitness_function(chromosome,x_df,y_df)  #calculate all fitness score of chromosome in population\n",
        "    fit_score.append(score)             #append it fit_score list\n",
        "\n",
        "#roullete wheel method\n",
        "  total_score=sum(fit_score)           #calculate sum of all fit score for probability\n",
        "  selection_probability=[]\n",
        "  for chromosome_fitness in fit_score:   #itrate fit_score for calculating probability\n",
        "    selection_probability.append(chromosome_fitness/total_score) #calculate probabiltiy of all chromosome based on thier fitness score/total score and apend to select probability\n",
        "  parent=choices(population,weights=selection_probability,k=2)       #select 2 parents(k=2) from the population by passing probability\n",
        "  return parent      # we will select two parents and return them to the calling function.\n",
        "\n",
        "\n",
        "#crossover , single point crossover..\n",
        "def crossover(parent1,parent2):\n",
        "  cross_over_point=randint(1,len(parent1)-1)   #generate a random index.. from 1 to length-1\n",
        "  offspring1=parent1[:cross_over_point]+parent2[cross_over_point:]  #and do the crossover..  cut and append\n",
        "  offspring2=parent2[:cross_over_point]+parent1[cross_over_point:]  #smilarliy generate offspring2 based on cross_over_point slice it\n",
        "  return offspring1,offspring2  #return two produced offsprings\n",
        "\n",
        "\n",
        "#mutation\n",
        "def mutation(child1, mut_prob):\n",
        "\n",
        "  index=randint(0,len(child1)-1)    #generate random index for mutate ith position of offspring\n",
        "\n",
        "  # child1 = toList(child1)\n",
        "  if(mut_prob > random()):     #select a random number from 0-1 and if it is smaller than mutation probabity than flip\n",
        "    if(child1[index]==1):            #a bit at randomly generated index..\n",
        "      child1[index]=0              #mutate index bit\n",
        "    else:\n",
        "      child1[index]=1\n",
        "  return child1\n",
        "\n",
        "\n",
        "\n",
        "#this is our main alog part that will run the whlole genetic algo part..\n",
        "\n",
        "def genetic_algo(population,generation,population_size,x_df,y_df):\n",
        "    popul=selection(population,x_df,y_df)    #selected a population parameter(population,ith generation)\n",
        "    new_population=[]\n",
        "    for j in range(int(population_size/2)):   #run the loop iterate by increment of j =2\n",
        "       parent1,parent2=select_parent(popul,x_df,y_df)   #select two parents  passes parameter\n",
        "       child1,child2= crossover(parent1, parent2)   #and senf them for crossover..\n",
        "       child1 = mutation(child1,mutation_rate)  #then do mutation  .\n",
        "       child2 = mutation(child2, mutation_rate)\n",
        "       new_population.append(child1)\n",
        "       new_population.append(child2)    #append to the new generation\n",
        "    population = new_population           #made this new generation as our population and go in the loop again..\n",
        "    return population"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nuxVzcawz1I-"
      },
      "outputs": [],
      "source": [
        "def start_genatics(population_size,generation,x_df,y_df):\n",
        "    population = init_population(population_size,x_df)   #initialize intial population by calling init_population\n",
        "    fitness_score=[]\n",
        "    for i in range(len(population)):\n",
        "      score=fitness_function(population[i],x_df,y_df)\n",
        "      fitness_score.append(score)                      #calculate fitness score for initial population\n",
        "      sorted_indices = np.argsort(fitness_score)[::-1]  #sort in descending order\n",
        "    t=0\n",
        "    list_ans = []\n",
        "    list_ans.append([population[sorted_indices[0]],fitness_function(population[sorted_indices[0]],x_df,y_df)])  #append initial population bestest\n",
        "    while t<generation:\n",
        "       update_pop=genetic_algo(population,generation,population_size,x_df,y_df)   #call to the main algo function.\n",
        "       fitness_score=[]\n",
        "       for i in range(len(update_pop)):\n",
        "           score=fitness_function(update_pop[i],x_df,y_df)\n",
        "           fitness_score.append(score)                        #again calculate fitness score\n",
        "       sorted_indices = np.argsort(fitness_score)[::-1]  #sort in descending order\n",
        "       list_ans.append([update_pop[sorted_indices[0]],fitness_function(update_pop[sorted_indices[0]],x_df,y_df)])   #store best one\n",
        "       population=update_pop       #initialize pop to update population\n",
        "       t=t+1                       #gentration increment\n",
        "    return list_ans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "t7CZ4j1I2mIz"
      },
      "outputs": [],
      "source": [
        "def main(x_df,y_df):\n",
        "  res=[]\n",
        "  for k in range(len(population_size)):\n",
        "     for m in range(len(generation_size)):\n",
        "      genetic_ans = start_genatics(population_size[k],generation_size[m],x_df,y_df)\n",
        "      genetic_ans = pd.DataFrame(genetic_ans)\n",
        "      result=genetic_ans.sort_values(by=1,ascending=False)  #sort dataframe in descending order based on fitness score by selecting column 1\n",
        "      # print(result.head(10))\n",
        "      # result_df.head(10)\n",
        "      selected_ft=result.iloc[0][0]     #get 0th row 1th chromosome(selected_features which gives heigest performans)\n",
        "      # print(\"total Features\",len(cell_value))     #print number of feature\n",
        "      count_OfSelceted_ft = selected_ft.count(1)               #calculate number of feature has been selected\n",
        "      # print(\"selected features=\",count_OfSelceted_ft )         #print selected feature\n",
        "      accuracyScore=fitness_function(selected_ft,x_df,y_df)     #calculate best chromosome score\n",
        "      # print(\"accuracy=\",accuracyScore)\n",
        "      res.append([population_size[k],generation_size[m],selected_ft,x_df.shape[1],count_OfSelceted_ft,accuracyScore])\n",
        "  return res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byWThlt783GT"
      },
      "source": [
        "**Global Search**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8z2S9a080MU"
      },
      "outputs": [],
      "source": [
        "df1=pd.read_csv(r'uploaded_file.csv')\n",
        "\n",
        "# df1=df1.drop('ID',axis=1)\n",
        "# print(df1.shape[1])\n",
        "\n",
        "# from sklearn import preprocessing\n",
        "# en=preprocessing.LabelEncoder()            #by LabelProcessing\n",
        "# df1['class']=en.fit_transform(df1['class'])\n",
        "\n",
        "x1_df = df1.iloc[:, 0:-1]\n",
        "y1_df= df1.drop(df1.iloc[:, 0:-1], axis=1)\n",
        "res= main(x1_df,y1_df)\n",
        "res= pd.DataFrame(res)\n",
        "res.columns =['Population', 'Generation', 'selected_features','total_features','total_selected_faetues','Accuracy']\n",
        "# res.to_csv(\"/content/GlobalResult.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qgr-hozQCixh"
      },
      "source": [
        "**Sort Result in Descending Order**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQN-t1XBCqc8"
      },
      "outputs": [],
      "source": [
        "result=res.sort_values(by='Accuracy',ascending=False)  #sort dataframe in descending order based on fitness score by selecting column 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tifbIiqICzvO"
      },
      "source": [
        "**Select feature With heigest Acuuracy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFvOq6ezC7dC",
        "outputId": "7fe3a01c-c38a-42f7-94ae-adae781f79d5"
      },
      "outputs": [],
      "source": [
        "s1_ft=result.iloc[0][2]     #get 0th row 1th habitate(selected_features which gives heigest performans)\n",
        "# print(\"selected features is:\",s1_ft)\n",
        "# print(\"Total number of features \",result.iloc[0][3] )\n",
        "# print(\"total selected Features\",result.iloc[0][4])     #print number of feature\n",
        "best_score=result.iloc[0][5]    #calculate best habitate vscore\n",
        "# print(\"accuracy=\",best_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFru195tDiRU"
      },
      "source": [
        "**This final function is used for Local Search**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5aCTRQ54DoL2"
      },
      "outputs": [],
      "source": [
        "def final(best_score,s_ft,max_sc,n1,xxdf,yydf,ft_dataset):\n",
        " numft=len(s_ft)\n",
        " if(best_score>=max_sc):\n",
        "  minimize2_df=select_feature(s_ft,xxdf)\n",
        "  # dataset=\"/content/With_\"+str(numft)+\"_Feature_Dataset.csv\"   #for create selected feature dataset for each itration\n",
        "  max_sc=best_score\n",
        "  ans=main(minimize2_df,yydf)\n",
        "  ans= pd.DataFrame(ans)\n",
        "  ans.columns =['Population', 'Generation', 'selected_features','total_features','total_selected_faetues','Accuracy']\n",
        "  # st=\"/content/Local_Search_Iteration5_result_\"+str(n1)+\".csv\"     #for create result csv for each itration\n",
        "  # ans.to_csv(st)\n",
        "  n1=int(n1)\n",
        "  n1=n1+1\n",
        "  result=ans.sort_values(by='Accuracy',ascending=False)  #sort dataframe in descending order based on fitness score by selecting column 1\n",
        "  select_ft=result.iloc[0][2]     #get 0th row 1th habitate(selected_features which gives heigest performans)\n",
        "  best_sc=result.iloc[0][5]    #calculate best habitate vscore\n",
        "  minimize2_df = pd.concat([minimize2_df,y1_df], axis=1)\n",
        "  # minimize2_df.to_csv(dataset,index=False)        #for generate dataset\n",
        "  ft_dataset=minimize2_df\n",
        "  y2_df= minimize2_df.drop(minimize2_df.iloc[:, 0:-1], axis=1)\n",
        "  final(best_sc,select_ft,max_sc,n1,minimize2_df,yydf,ft_dataset)\n",
        " else:\n",
        "#   dataset=\"/content/With_\"+str(numft)+\"_Feature_Dataset.csv\"   #for create selected feature dataset for each itration\n",
        "  ft_dataset.to_csv('result.csv',index=False)        #for generate dataset\n",
        "  # print(\"Search is Ended With best Result with \"+str(n1)+\" Itration\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hB4E7JXYD3e3"
      },
      "source": [
        "**Call Final Function for Local Search**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzXFL4abD6xw"
      },
      "outputs": [],
      "source": [
        "n=1              #set n=1 to itration How many local search Done\n",
        "max_score=0       #intialize max_score\n",
        "final_dataset=pd.DataFrame()\n",
        "final(best_score,s1_ft,max_score,n,x1_df,y1_df,final_dataset)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "My Environment",
      "language": "python",
      "name": "venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
