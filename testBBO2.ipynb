{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nA8kwfQsbhnq"
      },
      "source": [
        "**Apply BBO**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "qPw7OegPK3uh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split,cross_val_score\n",
        "from sklearn import datasets\n",
        "from sklearn.metrics import accuracy_score\n",
        "from random import choices , randint, randrange , random,uniform\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "\n",
        "\n",
        "# Define the BBO algorithm parameters\n",
        "population_size = [5]          #automate\n",
        "generation_size= [10]\n",
        "m = 0.01            #User Define mutation Parameter\n",
        "\n",
        "#this function will generate a list of 0 and 1,of lenght equal to the total number of habitat in dataset\n",
        "#basically it will create our habitat..\n",
        "# num_features = x_df.shape[1]    #number of features\n",
        "def generate_habitat(x_df):\n",
        "    num_features = x_df.shape[1]    #number of features\n",
        "    return [randint(0, 1) for _ in range(num_features)]\n",
        "\n",
        "#this population will create our population\n",
        "#it will call generate_habitat() function number of times = population_size and and append all chromosome into list return a population\n",
        "\n",
        "def init_population(p,x_df):\n",
        "  population = []\n",
        "  for i in range(p):\n",
        "    habitat=generate_habitat(x_df)\n",
        "    select_feture_column=select_feature(habitat)\n",
        "    population.append(select_feture_column)\n",
        "  return population\n",
        "\n",
        "# convert actual habitat into seleccted features dataframe\n",
        "# this function will iterate over our habitat and the indices it will find 1, it will add the feature of that indices to our\n",
        "# new DataFrame\n",
        "def select_feature(habitat):\n",
        "   ct=0\n",
        "   for i in habitat:        #if habitat generate[0,0,0,0,......] No feature selected thorw error\n",
        "     if i==0:\n",
        "      ct+=1\n",
        "   if ct==len(habitat):          #if count is equal to length of habitat flip 0th bit\n",
        "     habitat[0]=1\n",
        "   feature_column=[]\n",
        "   for i in range(len(habitat)):\n",
        "      if(habitat[i]==1):\n",
        "         feature_column.append(i)\n",
        "  #  print(feature_column)\n",
        "   return feature_column\n",
        "\n",
        "def select_feature_DataFrame(habitat,x_df):\n",
        "  # print(x_df.shape[1])\n",
        "  new_df=pd.DataFrame()\n",
        "  for i in habitat:\n",
        "      new_df = pd.concat([new_df, x_df[x_df.columns[i]]], axis=1)\n",
        "  return new_df\n",
        "\n",
        "def fitness_function(habitat,x_df,y_df):\n",
        "  select_feature_df=pd.DataFrame()\n",
        "  select_feature_df=select_feature_DataFrame(habitat,x_df)      #returns selected features DataFrame\n",
        "\n",
        "  xtrain , xtest, ytrain, ytest = train_test_split(select_feature_df, y_df,test_size=0.30,random_state=30)            #split selected feature dataframe traing and testing\n",
        "  clf= RandomForestClassifier(max_depth=None,min_samples_leaf=1,min_samples_split=2,n_estimators=150)\n",
        "  # score = np.mean(cross_val_score(clf,x_df,y_df.values.ravel(),cv=15))\n",
        "  clf.fit(xtrain,ytrain.values.ravel())      #train classifier\n",
        "  y_predict=clf.predict(xtest)\n",
        "  score=accuracy_score(ytest,y_predict)    #calculate accuracy score between test target and predicted target\n",
        "  return score\n",
        "\n",
        "def immigration(sorted_indices,population_len):\n",
        "  immigr=np.zeros([len(sorted_indices),1],dtype=\"float\")\n",
        "  for i in range(len(sorted_indices)):\n",
        "    k=i+1\n",
        "    lemda_k=(1-(k/population_len))\n",
        "    immigr[sorted_indices[i],0]=lemda_k\n",
        "  return immigr\n",
        "\n",
        "\n",
        "def emmigration(sorted_indices,population_len):\n",
        "  emmigr=np.zeros([population_len,1],dtype=\"float\")\n",
        "  for i in range(len(sorted_indices)):\n",
        "    k=i+1\n",
        "    lemda_u=(k/population_len)\n",
        "    emmigr[sorted_indices[i],0]=lemda_u\n",
        "    # print(emmigr[sorted_indices[i],0])\n",
        "  return emmigr\n",
        "\n",
        "#this function used to calculate mutation rate of each habitate in population by formula m(s) = m * ((1 - p(s))/p(max))\n",
        "\"\"\"m(s): the mutation rate for the solution s\n",
        "m: the mutation rate parameter, which is a constant value\n",
        "p(s): the fitness probability of solution s\n",
        "p(max): the maximum fitness probability in the population\n",
        "\n",
        "p(s) = f(s) / sum(f(i))\n",
        "p(s) probability of fitness score each fitness score divide by total fitness score \"\"\"    #comment\n",
        "def mutation_rate_compute(update_pop,population_len,x_df,y_df):\n",
        "   fitness_score=[]\n",
        "   for i in range(len(update_pop)):\n",
        "        score=fitness_function(update_pop[i],x_df,y_df)\n",
        "        fitness_score.append(score*100)                #calculate fitness score\n",
        "   sorted_indices = np.argsort(fitness_score)[::-1]  #sort in descending order\n",
        "   muted_rate_arr=np.zeros([population_len,1],dtype=\"float\")           #create an array that store mutation rate with corresponding Habitate index\n",
        "  #  total_habitate_fitness=sum(fitness_score)           #sum up all fitnesss score for calculating probability\n",
        "   Ps=[]                                #empty list for calculating each habitate fitness probability\n",
        "  #  for score in fitness_score:\n",
        "  #         Ps.append(score/total_habitate_fitness)            #calculate fitness probability and append into a list\n",
        "   for j in range(len(sorted_indices)):\n",
        "          k=j+1\n",
        "          Ps.append(k/len(update_pop))\n",
        "   Pmax=max(Ps)                                                #also find maximum probability\n",
        "   for i in range(len(update_pop)):\n",
        "     mutation_rate=m*((1-Ps[i])/Pmax)                            #apply formula for evaluate mutation rate for each habitate\n",
        "     muted_rate_arr[i,0]=mutation_rate                 #append it to an array\n",
        "\n",
        "   return muted_rate_arr                                       #return mutation rate array\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# n_features = x_df.shape[1]     # number of features\n",
        "#perfrom mutation\n",
        "def new_mutation(muted_rate_arr,pop,x_df,y_df):\n",
        "  for i in range(len(pop)):\n",
        "    n_features = x_df.shape[1]\n",
        "    if uniform(0,1)<muted_rate_arr[i,0]:\n",
        "      prev_score=fitness_function(pop[i],x_df,y_df)               #calculate score of habitat without mutation\n",
        "      prev_habitat=pop[i]                               #store previous habitat without mutation\n",
        "      indx=randint(0,len(pop[i])-1)        #generate an index in betwwen 0 to length of habitate\n",
        "      num=randint(0,n_features-1)           #genetrate a number 0 to number of features\n",
        "      if num not in pop[i]:                  #check if number is not present in habitate\n",
        "        pop[i][indx]=num                     #then replace Habitate SIV with number\n",
        "      update_score=fitness_function(pop[i],x_df,y_df)   #calculate habitat score after mutation\n",
        "      if(update_score<prev_score):            #if after mutation habitat score increases then change the current habitat\n",
        "         pop[i]=prev_habitat\n",
        "  return pop                                  #return population\n",
        "\n",
        "\n",
        "# n_features = x_df.shape[1]     # number of features\n",
        "def new_migration(pop,immigr,emmigr,x_df):\n",
        "  n_features = x_df.shape[1]     # number of features\n",
        "  for i in range(len(pop)):\n",
        "    if uniform(0,1)<immigr[i,0]:\n",
        "      for j in range(len(pop)):\n",
        "        if uniform(0,1)<emmigr[i,0]:\n",
        "          # print(\"before migration pop[j]=\",pop[i])\n",
        "          if(len(pop[i])<=len(pop[j])):\n",
        "            H_E_indx=randint(0,len(pop[i])-1)\n",
        "            H_I_indx=randint(0,len(pop[i])-1)\n",
        "          else:\n",
        "             H_E_indx=randint(0,len(pop[j])-1)\n",
        "             H_I_indx=randint(0,len(pop[j])-1)\n",
        "          p1=pop[j][H_E_indx]        #emigration element extract\n",
        "          if p1 not in pop[i]:           #if emigrated SIV is not present in Immigrated Habitate\n",
        "             pop[i][H_I_indx]=p1         #replace SIV in immegrated habitate\n",
        "          else:\n",
        "            pop[i]=pop[i]             #else not replace immigrated habitate\n",
        "\n",
        "  return pop                # return population\n",
        "\n",
        "\n",
        "def runBBO(population_len,generation,x_df,y_df):\n",
        "    pop=init_population(population_len,x_df)\n",
        "    fitness_score=[]\n",
        "    for i in range(len(pop)):\n",
        "      score=fitness_function(pop[i],x_df,y_df)\n",
        "      fitness_score.append(score)                      #calculate fitness score for initial population\n",
        "      sorted_indices = np.argsort(fitness_score)[::-1]  #sort in descending order\n",
        "    t=0\n",
        "    list_ans = []\n",
        "    list_ans.append([pop[sorted_indices[0]],fitness_function(pop[sorted_indices[0]],x_df,y_df)])  #append initial population bestest\n",
        "    while t<generation:\n",
        "        # print(\"generation=\",t)\n",
        "        immi_arr = immigration(sorted_indices,population_len)\n",
        "        emmi_arr = emmigration(sorted_indices,population_len)\n",
        "        update_pop=new_migration(pop, immi_arr, emmi_arr,x_df)        #perform migration  and return updated population\n",
        "        mutation_rate=mutation_rate_compute(update_pop,population_len,x_df,y_df)       #compute mutation rate of updated population\n",
        "        muteted_pop=new_mutation(mutation_rate,update_pop,x_df,y_df)         #perform mutaion and return mutated population\n",
        "        fitness_score=[]\n",
        "        for i in range(len(update_pop)):\n",
        "           score=fitness_function(update_pop[i],x_df,y_df)\n",
        "           fitness_score.append(score)                        #again calculate fitness score\n",
        "        sorted_indices = np.argsort(fitness_score)[::-1]  #sort in descending order\n",
        "        list_ans.append([update_pop[sorted_indices[0]],fitness_function(update_pop[sorted_indices[0]],x_df,y_df)])   #store best one\n",
        "        pop=update_pop       #initialize pop to update population\n",
        "        t=t+1                       #gentration increment\n",
        "    return list_ans\n",
        "\n",
        "              #print accuracy score of that habitate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6X-243DExhpM"
      },
      "source": [
        " this function run BBO for number of generation and population\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "pWbDKXXlaVf6"
      },
      "outputs": [],
      "source": [
        "def main(x_df,y_df):\n",
        "  res=[]\n",
        "  for k in range(len(population_size)):\n",
        "     for m in range(len(generation_size)):\n",
        "      BBO_ans = runBBO(population_size[k],generation_size[m],x_df,y_df)\n",
        "      BBO_ans = pd.DataFrame(BBO_ans)\n",
        "      result=BBO_ans.sort_values(by=1,ascending=False)  #sort dataframe in descending order based on fitness score by selecting column 1\n",
        "      # print(result)\n",
        "      # result_df.head(10)\n",
        "      selected_ft=result.iloc[0][0]     #get 0th row 1th habitate(selected_features which gives heigest performans)\n",
        "      # print(\"selected features is:\",selected_ft)\n",
        "      # print(\"Total number of features \",x_df.shape[1])\n",
        "      # print(\"total selected Features\",len(selected_ft))     #print number of feature\n",
        "      best_score=result.iloc[0][1]    #calculate best habitate vscore\n",
        "      # print(\"accuracy=\",best_score)\n",
        "      res.append([population_size[k],generation_size[m],selected_ft,x_df.shape[1],len(selected_ft),best_score])\n",
        "  return res;\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7v8o85cxy6C"
      },
      "source": [
        "**Global Search**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlSIF-5gNhNo",
        "outputId": "f41af05b-69a5-4777-8425-13f36e42d9c7"
      },
      "outputs": [],
      "source": [
        "df1=pd.read_csv(r'uploaded_file.csv')\n",
        "\n",
        "# df1=df1.drop('ID',axis=1)\n",
        "# print(df1.shape[1])\n",
        "\n",
        "# from sklearn import preprocessing\n",
        "# en=preprocessing.LabelEncoder()            #by LabelProcessing\n",
        "# df1['class']=en.fit_transform(df1['class'])\n",
        "\n",
        "x1_df = df1.iloc[:, 0:-1]\n",
        "y1_df= df1.drop(df1.iloc[:, 0:-1], axis=1)\n",
        "res= main(x1_df,y1_df)\n",
        "res= pd.DataFrame(res)\n",
        "res.columns =['Population', 'Generation', 'selected_features','total_features','total_selected_faetues','Accuracy']\n",
        "# res.to_csv(\"/content/GlobalResultIteration5.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMW6QE81x_1G"
      },
      "source": [
        "**Sort Result in Descending Order**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "497XkrjkNu5z",
        "outputId": "7e28bce6-71a0-4db0-978f-5b95aa8b1c02"
      },
      "outputs": [],
      "source": [
        "result=res.sort_values(by='Accuracy',ascending=False)  #sort dataframe in descending order based on fitness score by selecting column 1\n",
        "# print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9u2sD5hyVDA"
      },
      "source": [
        "**Select feature With heigest Acuuracy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBlcyHP9T0E6",
        "outputId": "c7a754f6-5a19-4ccc-9e74-8f8ac2886820"
      },
      "outputs": [],
      "source": [
        "s1_ft=result.iloc[0][2]     #get 0th row 1th habitate(selected_features which gives heigest performans)\n",
        "# print(\"selected features is:\",s1_ft)\n",
        "# print(\"Total number of features \",x1_df.shape[1])\n",
        "# print(\"total selected Features\",len(s1_ft))     #print number of feature\n",
        "best_score=result.iloc[0][5]    #calculate best habitate vscore\n",
        "# print(\"accuracy=\",best_score)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcdoZyHfyhO_"
      },
      "source": [
        "**This final function is used for Local Search**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "TBei42TYMez2"
      },
      "outputs": [],
      "source": [
        "def final(best_score,s_ft,max_sc,n1,xxdf,yydf,ft_dataset):\n",
        " numft=len(s_ft)\n",
        " if(best_score>=max_sc):\n",
        "  minimize2_df=select_feature_DataFrame(s_ft,xxdf)\n",
        "  # dataset=\"With_\"+str(numft)+\"_Feature_Dataset.csv\"   #for create selected feature dataset for each itration\n",
        "  max_sc=best_score\n",
        "  ans=main(minimize2_df,yydf)\n",
        "  ans= pd.DataFrame(ans)\n",
        "  ans.columns =['Population', 'Generation', 'selected_features','total_features','total_selected_faetues','Accuracy']\n",
        "  # st=\"/content/Local_Search_Iteration5_result_\"+str(n1)+\".csv\"     #for create result csv for each itration\n",
        "  # ans.to_csv(st)\n",
        "  n1=int(n1)\n",
        "  n1=n1+1\n",
        "  result=ans.sort_values(by='Accuracy',ascending=False)  #sort dataframe in descending order based on fitness score by selecting column 1\n",
        "  select_ft=result.iloc[0][2]     #get 0th row 1th habitate(selected_features which gives heigest performans)\n",
        "  best_sc=result.iloc[0][5]    #calculate best habitate vscore\n",
        "  minimize2_df = pd.concat([minimize2_df,y1_df], axis=1)\n",
        "  # minimize2_df.to_csv(dataset,index=False)        #for generate dataset\n",
        "  ft_dataset=minimize2_df\n",
        "  y2_df= minimize2_df.drop(minimize2_df.iloc[:, 0:-1], axis=1)\n",
        "  final(best_sc,select_ft,max_sc,n1,minimize2_df,yydf,ft_dataset)\n",
        " else:\n",
        "  #dataset=\"/content/With_\"+str(numft)+\"_Feature_Dataset_iteration5.csv\"   #for create selected feature dataset for each itration\n",
        "  # output_file = \"result.csv\"\n",
        "  # file=\"final_result.csv\"\n",
        "  ft_dataset.to_csv('result.csv', index=False)        #for generate dataset\n",
        "  # print(\"Search is Ended With best Result with \"+str(n1)+\" Itration\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0mdwUoHzQEl"
      },
      "source": [
        "**Call Final Function for Local Search**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-KSAFRJQ_qB",
        "outputId": "c077c190-fca1-402e-9c4b-a7e4fddc13cf"
      },
      "outputs": [],
      "source": [
        "n=1              #set n=1 to itration How many local search Done\n",
        "max_score=0       #intialize max_score\n",
        "final_dataset=pd.DataFrame()\n",
        "final(best_score,s1_ft,max_score,n,x1_df,y1_df,final_dataset)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "My Environment",
      "language": "python",
      "name": "venv"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
