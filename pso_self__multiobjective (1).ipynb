{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbSXRc8EUfuw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from random import uniform, randint\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FoxqnOFwUfuy"
      },
      "outputs": [],
      "source": [
        "def initialize_positions(no_of_particles, dimensions):\n",
        "    positions = np.zeros([no_of_particles, dimensions],dtype='float')\n",
        "\n",
        "    for i in range(no_of_particles):\n",
        "        for j in range(dimensions):\n",
        "            positions[i,j]= abs(uniform(0,1) - uniform(0,1))\n",
        "\n",
        "    return positions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3KzskZpTUfuy"
      },
      "outputs": [],
      "source": [
        "def initilize_velocities(no_of_particles, dimensions):\n",
        "    velocities = np.zeros([no_of_particles,dimensions],dtype='float')\n",
        "\n",
        "    for i in range(no_of_particles):\n",
        "        for j in range(dimensions):\n",
        "            velocities[i,j] = abs(uniform(0,1)-uniform(0,1))\n",
        "\n",
        "    return velocities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIbZKKHPUfuz"
      },
      "outputs": [],
      "source": [
        "def to_binary(positions,threshold, no_of_particles,dimensions):\n",
        "    binary_positions = np.zeros([no_of_particles, dimensions])\n",
        "\n",
        "    for i in range(no_of_particles):\n",
        "        for j in range(dimensions):\n",
        "            if positions[i,j]>=threshold:\n",
        "                binary_positions[i,j] = 1\n",
        "            else:\n",
        "                binary_positions[i,j]=0\n",
        "\n",
        "    return binary_positions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIIw7WzAYSH4"
      },
      "outputs": [],
      "source": [
        "def findFeatures(particle):\n",
        "    features=[]\n",
        "    for i in range(len(particle)):\n",
        "      if particle[i]==1:\n",
        "        features.append(i)\n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_j74JAWCUfuz"
      },
      "outputs": [],
      "source": [
        "def fitness_function(particle,xtrain,xtest,ytrain,ytest):\n",
        "    ct=0\n",
        "\n",
        "    for i in range(len(particle)):\n",
        "        if particle[i]==1:\n",
        "            ct+=1\n",
        "\n",
        "    if(ct==0):\n",
        "        index = randint(0,len(particle)-1)\n",
        "        particle[index]=1\n",
        "\n",
        "    features = findFeatures(particle)\n",
        "    num_train = np.size(xtrain, 0)\n",
        "    num_test = np.size(xtest, 0)\n",
        "\n",
        "    new_xtrain = xtrain.iloc[:,features]\n",
        "    new_xtest = xtest.iloc[:,features]\n",
        "    new_ytrain = ytrain\n",
        "    new_ytest = ytest\n",
        "\n",
        "    decision_model = DecisionTreeClassifier(criterion='gini')\n",
        "\n",
        "    decision_model.fit(new_xtrain, new_ytrain)\n",
        "\n",
        "    predictions = decision_model.predict(new_xtest)\n",
        "\n",
        "    score = accuracy_score(ytest, predictions)\n",
        "\n",
        "    return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HgLqI_GwUfu0"
      },
      "outputs": [],
      "source": [
        "# main function that will run the PSO and working of the PSO\n",
        "\n",
        "def run_PSO(w, c1, c2, no_of_particles, maximum_iterations, threshold,xtrain,xtest,ytrain,ytest):\n",
        "\n",
        "    # here first we are going to initialize some variables that will help us in\n",
        "    # finding the initial positions and the initial velocities\n",
        "\n",
        "    # these are some of the varibale we will be using, we we will update te velocities and the position\n",
        "\n",
        "    # so first we have created two arrays upper and lower bounds that will be used in\n",
        "    # calculations of the intial positions and the velocities\n",
        "\n",
        "    dimensions = np.size(xtrain, 1)\n",
        "\n",
        "    # here we are calling our initial_positions() functions to get the initial positionS  of the particles..\n",
        "    positions = initialize_positions(\n",
        "        no_of_particles, dimensions)\n",
        "\n",
        "    # similarly for initial velocities -> obviously both will ghet some random variables\n",
        "    velocities = initilize_velocities(\n",
        "        no_of_particles, dimensions)\n",
        "\n",
        "    # here we have created some matrices and vectors of zeros ,and some variables to store the postions , best positions, fitenss, best_fitness etc\n",
        "    # names are self explanatory here\n",
        "\n",
        "    fitness_of_particles = np.zeros([no_of_particles, 1], dtype='float')\n",
        "    best_fitness_of_particles = float('-inf')*np.ones([no_of_particles, 1], dtype='float')\n",
        "    global_best_fitness = float('-inf')\n",
        "    best_particle_position = np.zeros([no_of_particles, dimensions], dtype='float')\n",
        "    global_best_positions = np.zeros([1, dimensions], dtype='float')\n",
        "\n",
        "    # this matrices will store our global_best_fitness value at each iteration..\n",
        "\n",
        "    t = 0  # a variable to keep the counter of number of iterations.\n",
        "\n",
        "    # loop to keep the iterations on for the selection of the best result\n",
        "    while t < maximum_iterations:\n",
        "\n",
        "        # call to to_binary() functiion to convert matrices into values of ones and zeros only\n",
        "        position_bin = to_binary(positions, threshold, no_of_particles, dimensions)\n",
        "\n",
        "        # this loop will iterate through our population and for each particle it will find the fitness value and do the need full\n",
        "        for i in range(no_of_particles):\n",
        "            fitness_of_particles[i, 0] = fitness_function(position_bin[i, :],xtrain,xtest,ytrain,ytest)\n",
        "\n",
        "            # if(fitness of current particle is better than its previous best value -> then do this updation)\n",
        "            if fitness_of_particles[i, 0] >= best_fitness_of_particles[i, 0]:\n",
        "                # best_position will be updated to the current position\n",
        "                best_particle_position[i, :] = positions[i, :]\n",
        "                # and best fitness value will be updated to the current fitness value\n",
        "                best_fitness_of_particles[i, 0] = fitness_of_particles[i, 0]\n",
        "\n",
        "            # similarly if it is better than the global best value then update global best fitness value as well as the global best position\n",
        "            if best_fitness_of_particles[i, 0] >= global_best_fitness:\n",
        "                global_best_positions[0, :] = best_particle_position[i, :]\n",
        "\n",
        "                global_best_fitness = best_fitness_of_particles[i, 0]\n",
        "\n",
        "        t += 1\n",
        "        # print(\"Global_best_fitness: \", global_best_fitness)\n",
        "        # update the position and the velocity values of the variable of each particle and and move to the next iteration\n",
        "        for i in range(no_of_particles):\n",
        "            for d in range(dimensions):\n",
        "                r1 = uniform(0,1)\n",
        "                r2 = uniform(0,1)\n",
        "\n",
        "                # update velocity using this given formula here where c1 and c2 are accelaration factors, w is the inertia weight and r1 and r2 are random numbers\n",
        "                velocities[i, d] = w * velocities[i, d] + c1*r1*(\n",
        "                    best_particle_position[i, d]-positions[i, d]) + c2*r2*(global_best_positions[0, d]-positions[i, d])\n",
        "\n",
        "\n",
        "                # update the position also\n",
        "                positions[i, d] = positions[i, d] + velocities[i, d]\n",
        "\n",
        "    # the answers after the iterations complete and we are returning these values to aur calling function.\n",
        "    global_best_binary = to_binary(global_best_positions, threshold, 1, dimensions)\n",
        "    global_best_binary = global_best_binary.reshape(dimensions)\n",
        "    pos = np.asarray(range(0, dimensions))\n",
        "    selected_indexes = pos[global_best_binary == 1]\n",
        "    number_of_features_selected = len(selected_indexes)\n",
        "\n",
        "    pso_data = {'sf': selected_indexes,\n",
        "                'nf': number_of_features_selected, 'score': global_best_fitness}\n",
        "\n",
        "    return pso_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4S23-DxUfu3"
      },
      "outputs": [],
      "source": [
        "def start_pso(xtrain,xtest,ytrain,ytest, no_of_particles, maximum_iterations,threshold,total_num_ft):\n",
        "\n",
        "    c1 = 2\n",
        "    c2 = 2\n",
        "    w = 0.5\n",
        "    output_of_pso = run_PSO(\n",
        "          w, c1, c2, no_of_particles, maximum_iterations, threshold,xtrain,xtest,ytrain,ytest)\n",
        "\n",
        "    return [output_of_pso['score'],output_of_pso['sf']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSBngf14U6u_"
      },
      "outputs": [],
      "source": [
        "def init_local_pso(output_df,labels, no_of_particles, maximum_iterations):\n",
        "\n",
        "    threshold=0.5\n",
        "\n",
        "    features = output_df\n",
        "    total_num_ft = features.shape[1]\n",
        "\n",
        "    # data split for training and testing ..\n",
        "    xtrain, xtest, ytrain, ytest = train_test_split(features, labels, test_size=0.3, random_state=30)\n",
        "    returned_ans = start_pso(xtrain,xtest,ytrain,ytest, no_of_particles, maximum_iterations,threshold,total_num_ft)\n",
        "    return returned_ans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xMRmm1fXQHs"
      },
      "outputs": [],
      "source": [
        "best_score_all=0\n",
        "best_selected_df =[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cTZtgOehXFQL"
      },
      "outputs": [],
      "source": [
        "def local_pso(best_score, output_df,labels,no_of_particles, maximum_iterations):\n",
        "    global best_score_all, best_selected_ft\n",
        "    if(best_score>=best_score_all):\n",
        "        best_score_all = best_score\n",
        "        best_selected_df = output_df\n",
        "\n",
        "    print(\"best_updates: \",best_score_all)\n",
        "\n",
        "    ans = init_local_pso(output_df, labels, no_of_particles, maximum_iterations)\n",
        "\n",
        "    if(ans[0]>=best_score_all):\n",
        "        output_df = output_df.iloc[:, ans[1]].copy()\n",
        "        print(\"local_df\", output_df)\n",
        "        local_pso(ans[0],output_df,labels,no_of_particles, maximum_iterations)\n",
        "    else:\n",
        "        print(\"Best score ended: \",best_score_all)\n",
        "        print(\"Best susbset of ft ended: \", best_selected_df)\n",
        "        best_selected_df['labels'] = labels\n",
        "        best_selected_df.to_csv('result.csv',index=False)\n",
        "        return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGDe14XLV-7H"
      },
      "outputs": [],
      "source": [
        "def init_global_pso():\n",
        "    # path_csv = \"/content/DARWIN.csv\"\n",
        "\n",
        "    # no_of_particles = int(input(\"Enter number of particles: \\n\"))\n",
        "    # maximum_iterations = int(input(\"Enter the number of maximum iterations: \\n\"))\n",
        "    no_of_particles = 6\n",
        "    maximum_iterations = 10\n",
        "    # threshold = float(input(\"Enter the threshold value between(0-1): \\n\"))\n",
        "    threshold = 0.5\n",
        "\n",
        "    df1 = pd.read_csv(r'uploaded_file.csv')\n",
        "    # print(\"shape: \",df1.shape)\n",
        "    # df1 = df1.drop(['ID'],axis=1)\n",
        "    # label_encoder = LabelEncoder()\n",
        "\n",
        "    # # Fit and transform the 'class' column\n",
        "    # df1['class'] = label_encoder.fit_transform(df1['class'])\n",
        "\n",
        "    #Rename the column names\n",
        "    # df1.columns = range(1, len(df1.columns)+1)\n",
        "\n",
        "    features = df1.iloc[:, 0:-1]\n",
        "    labels = df1.drop(df1.iloc[:, 0:-1], axis=1)\n",
        "\n",
        "    total_num_ft = features.shape[1]\n",
        "\n",
        "        # data split for training and testing ..\n",
        "    xtrain, xtest, ytrain, ytest = train_test_split(features, labels, test_size=0.3, random_state=30)\n",
        "    returned_ans = start_pso(xtrain,xtest,ytrain,ytest, no_of_particles, maximum_iterations,threshold, total_num_ft)\n",
        "    output_df = df1.iloc[:, returned_ans[1]].copy()\n",
        "    local_pso(returned_ans[0], output_df,labels,no_of_particles, maximum_iterations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6U7RtOSWB7f"
      },
      "outputs": [],
      "source": [
        "init_global_pso()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gvqvy2LH3YWz",
        "outputId": "a7f3a7d2-b525-4d43-a713-8fa8f920d1b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9433962264150944\n"
          ]
        }
      ],
      "source": [
        "# import pandas as pd\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "# from sklearn.metrics import accuracy_score\n",
        "\n",
        "# # Sample dataset (replace this with your own data)\n",
        "# df = pd.read_csv('/content/final_dataset.csv')\n",
        "\n",
        "# # Separate features (X) and target (y)\n",
        "# features = df.iloc[:, 0:-1]\n",
        "# labels = df.drop(df.iloc[:, 0:-1], axis=1)\n",
        "\n",
        "# # Split the dataset into training and testing sets\n",
        "# X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=30)\n",
        "\n",
        "# # Initialize the DecisionTreeClassifier\n",
        "# clf = DecisionTreeClassifier()\n",
        "\n",
        "# # Train the classifier on the training data\n",
        "# clf.fit(X_train, y_train)\n",
        "\n",
        "# # Make predictions on the test data\n",
        "# y_pred = clf.predict(X_test)\n",
        "\n",
        "# # Evaluate the classifier's accuracy\n",
        "# accuracy = accuracy_score(y_test, y_pred)\n",
        "# print(\"Accuracy:\", accuracy)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
